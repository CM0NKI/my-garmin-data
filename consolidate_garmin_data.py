#!/usr/bin/env python3
"""Consolidate Garmin daily health data into a single token-efficient file.

Reads ~/garmin_data/daily/{YYYY-MM-DD}/*.json and ~/garmin_data/activities/*.json
and produces a single combined file:
  ~/garmin_data/claude_summary/garmin_data.csv

The file contains a header with instructions for Claude, followed by two CSV
sections: DAILY_METRICS and ACTIVITIES.

Incremental: only processes new days/activities on each run.
Original data is never modified.
"""

import csv
import io
import json
from pathlib import Path

GARMIN_DATA = Path.home() / "garmin_data"
DAILY_DIR = GARMIN_DATA / "daily"
ACTIVITIES_DIR = GARMIN_DATA / "activities"
BODY_COMP_FILE = GARMIN_DATA / "body_composition" / "body_comp.json"
WEIGH_INS_FILE = GARMIN_DATA / "body_composition" / "weigh_ins.json"
PERSONAL_RECORDS_FILE = GARMIN_DATA / "personal_records.json"
PROFILE_FILE = GARMIN_DATA / "profile" / "user_profile.json"
OUTPUT_DIR = GARMIN_DATA / "claude_summary"
STATE_FILE = OUTPUT_DIR / "processing_state.json"
COMBINED_FILE = OUTPUT_DIR / "garmin_data.csv"

HEADER_TEXT = """\
# GARMIN HEALTH & TRAINING DATA
#
# This file was auto-generated by consolidate_garmin_data.py for Claude to
# evaluate, correlate, and answer questions about the owner's health and
# training data from Garmin Connect.
#
# Sections:
#   1. PROFILE — static user info (gender, age, height, VO2max, lactate threshold)
#   2. DAILY_METRICS — one row per calendar day with health/wellness metrics
#   3. BODY_COMPOSITION — one row per weigh-in (weight, body fat, muscle mass, etc.)
#   4. ACTIVITIES — one row per recorded activity (workout, walk, hike, etc.)
#   5. PERSONAL_RECORDS — best performances (fastest 1K, longest run, etc.)
#
# DAILY_METRICS columns:
#   date                       — calendar date (YYYY-MM-DD)
#   steps, distance_m          — daily step count and total distance in meters
#   floors_asc, floors_desc    — floors climbed / descended
#   active_cal, total_cal, bmr_cal — kilocalories (active, total, basal metabolic rate)
#   highly_active_s, active_s, sedentary_s, sleeping_s — seconds in each activity level
#   moderate_im, vigorous_im   — intensity minutes (moderate / vigorous)
#   resting_hr, min_hr, max_hr — heart rate: resting, daily min, daily max
#   avg_stress, max_stress     — stress level (0-100 scale)
#   bb_high, bb_low, bb_charged, bb_drained — body battery (0-100): high/low/charged/drained
#   avg_waking_resp            — average waking respiration (breaths/min)
#   avg_spo2, lowest_spo2      — blood oxygen saturation %
#   sleep_s, sleep_deep_s, sleep_light_s, sleep_rem_s, sleep_awake_s — sleep duration breakdown (seconds)
#   sleep_score                — Garmin sleep score (0-100)
#   sleep_avg_stress           — average stress during sleep
#   sleep_awake_count          — number of awakenings
#   sleep_resting_hr           — resting heart rate during sleep
#   sleep_bb_change            — body battery change during sleep
#   sleep_avg_resp             — average respiration during sleep (breaths/min)
#   sleep_skin_temp_dev_c      — skin temperature deviation from baseline (Celsius)
#   hrv_weekly_avg, hrv_night_avg, hrv_5min_high — heart rate variability (ms)
#   hrv_status                 — HRV status (BALANCED, UNBALANCED, LOW, etc.)
#   tr_score, tr_level, tr_recovery_time — training readiness score/level/recovery hours
#   hydration_ml, hydration_goal_ml, sweat_loss_ml — fluid intake and loss (mL)
#   stress_avg, stress_max     — from stress.json (may duplicate summary values)
#   resp_avg_waking, resp_avg_sleep — respiration averages from respiration.json
#
# BODY_COMPOSITION columns:
#   date                       — weigh-in date (YYYY-MM-DD)
#   weight_kg                  — body weight in kilograms
#   bmi                        — body mass index
#   body_fat_pct               — body fat percentage
#   body_water_pct             — body water percentage
#   bone_mass_g                — bone mass in grams
#   muscle_mass_g              — muscle mass in grams
#
# ACTIVITIES columns:
#   id                         — Garmin activity ID
#   date                       — activity date (YYYY-MM-DD)
#   type                       — activity type key (indoor_cardio, walking, running, hiking, indoor_rowing, etc.)
#   name                       — activity name
#   duration_s                 — total duration in seconds
#   moving_s                   — moving duration in seconds (excludes pauses)
#   distance_m                 — distance in meters
#   calories                   — total kilocalories burned
#   avg_hr, max_hr, min_hr     — heart rate during activity
#   avg_speed_mps              — average speed in meters/sec (multiply by 3.6 for km/h)
#   elevation_gain_m, elevation_loss_m — elevation change in meters
#   training_effect, anaerobic_te — aerobic/anaerobic training effect (0-5 scale)
#   training_load              — activity training load
#   avg_cadence                — average running/walking cadence (steps/min)
#   avg_power, max_power       — power in watts (running/cycling)
#   moderate_im, vigorous_im   — intensity minutes earned
#   steps                      — step count during activity
#   bb_change                  — body battery change from this activity
#
# PERSONAL_RECORDS columns:
#   type                       — record type (1km, 1mi, 5km, 10km, longest_run, longest_ride, etc.)
#   value                      — record value (seconds for time records, meters for distance)
#   activity_type              — sport (running, cycling, etc.)
#   activity_name              — name of the activity where the record was set
#   date                       — date the record was set (YYYY-MM-DD)
#
# Notes:
# - Empty cells mean the metric was not available for that day/activity
# - Body battery ranges 0-100; stress ranges 0-100
# - Training effect: 0-1 none, 1-2 minor, 2-3 maintaining, 3-4 improving, 4-5 highly improving
# - HRV status: BALANCED is normal; UNBALANCED/LOW may indicate fatigue or stress
# - Training readiness: higher is better; level can be PRIME, HIGH, MODERATE, LOW
# - Durations are in seconds; divide by 3600 for hours
# - Weight is in kilograms (raw Garmin value divided by 1000)
# - Bone/muscle mass are in grams
"""

DAILY_COLUMNS = [
    "date",
    "steps", "distance_m", "floors_asc", "floors_desc",
    "active_cal", "total_cal", "bmr_cal",
    "highly_active_s", "active_s", "sedentary_s", "sleeping_s",
    "moderate_im", "vigorous_im",
    "resting_hr", "min_hr", "max_hr",
    "avg_stress", "max_stress",
    "bb_high", "bb_low", "bb_charged", "bb_drained",
    "avg_waking_resp", "avg_spo2", "lowest_spo2",
    "sleep_s", "sleep_deep_s", "sleep_light_s", "sleep_rem_s", "sleep_awake_s",
    "sleep_score", "sleep_avg_stress", "sleep_awake_count",
    "sleep_resting_hr", "sleep_bb_change", "sleep_avg_resp", "sleep_skin_temp_dev_c",
    "hrv_weekly_avg", "hrv_night_avg", "hrv_5min_high", "hrv_status",
    "tr_score", "tr_level", "tr_recovery_time",
    "hydration_ml", "hydration_goal_ml", "sweat_loss_ml",
    "stress_avg", "stress_max",
    "resp_avg_waking", "resp_avg_sleep",
]

BODY_COMP_COLUMNS = [
    "date", "weight_kg", "bmi", "body_fat_pct", "body_water_pct",
    "bone_mass_g", "muscle_mass_g",
]

ACTIVITY_COLUMNS = [
    "id", "date", "type", "name",
    "duration_s", "moving_s", "distance_m", "calories",
    "avg_hr", "max_hr", "min_hr",
    "avg_speed_mps", "elevation_gain_m", "elevation_loss_m",
    "training_effect", "anaerobic_te", "training_load",
    "avg_cadence", "avg_power", "max_power",
    "moderate_im", "vigorous_im", "steps", "bb_change",
]

PR_COLUMNS = ["type", "value", "activity_type", "activity_name", "date"]

# Garmin PR typeId to human-readable name
PR_TYPE_NAMES = {
    1: "1km", 2: "1mi", 3: "5km", 4: "10km", 5: "half_marathon",
    6: "marathon", 7: "longest_run", 8: "longest_ride",
    9: "longest_ride_distance", 10: "longest_swim",
    11: "longest_ride_elevation", 12: "most_steps_day",
    13: "most_floors_day", 14: "most_active_cal_day",
    15: "most_distance_day", 16: "most_activities_week",
}


def load_json(path: Path):
    """Load a JSON file, returning None if missing or invalid."""
    try:
        return json.loads(path.read_text())
    except (FileNotFoundError, json.JSONDecodeError):
        return None


def g(data, *keys):
    """Safely get a nested value from dicts/lists."""
    for k in keys:
        if data is None:
            return None
        try:
            data = data[k]
        except (KeyError, IndexError, TypeError):
            return None
    return data


def extract_daily(date_dir: Path) -> dict:
    """Extract one row of daily metrics from a date folder."""
    date_str = date_dir.name
    row = {"date": date_str}

    # summary.json
    s = load_json(date_dir / "summary.json")
    if s:
        row["steps"] = g(s, "totalSteps")
        row["distance_m"] = g(s, "totalDistanceMeters")
        row["floors_asc"] = g(s, "floorsAscended")
        row["floors_desc"] = g(s, "floorsDescended")
        row["active_cal"] = g(s, "activeKilocalories")
        row["total_cal"] = g(s, "totalKilocalories")
        row["bmr_cal"] = g(s, "bmrKilocalories")
        row["highly_active_s"] = g(s, "highlyActiveSeconds")
        row["active_s"] = g(s, "activeSeconds")
        row["sedentary_s"] = g(s, "sedentarySeconds")
        row["sleeping_s"] = g(s, "sleepingSeconds")
        row["moderate_im"] = g(s, "moderateIntensityMinutes")
        row["vigorous_im"] = g(s, "vigorousIntensityMinutes")
        row["resting_hr"] = g(s, "restingHeartRate")
        row["min_hr"] = g(s, "minHeartRate")
        row["max_hr"] = g(s, "maxHeartRate")
        row["avg_stress"] = g(s, "averageStressLevel")
        row["max_stress"] = g(s, "maxStressLevel")
        row["bb_high"] = g(s, "bodyBatteryHighestValue")
        row["bb_low"] = g(s, "bodyBatteryLowestValue")
        row["bb_charged"] = g(s, "bodyBatteryChargedValue")
        row["bb_drained"] = g(s, "bodyBatteryDrainedValue")
        row["avg_waking_resp"] = g(s, "avgWakingRespirationValue")
        row["avg_spo2"] = g(s, "averageSpo2")
        row["lowest_spo2"] = g(s, "lowestSpo2")

    # sleep.json
    sl = load_json(date_dir / "sleep.json")
    if sl:
        d = g(sl, "dailySleepDTO") or {}
        row["sleep_s"] = g(d, "sleepTimeSeconds")
        row["sleep_deep_s"] = g(d, "deepSleepSeconds")
        row["sleep_light_s"] = g(d, "lightSleepSeconds")
        row["sleep_rem_s"] = g(d, "remSleepSeconds")
        row["sleep_awake_s"] = g(d, "awakeSleepSeconds")
        row["sleep_score"] = g(d, "sleepScores", "overall", "value")
        row["sleep_avg_stress"] = g(d, "avgSleepStress")
        row["sleep_awake_count"] = g(d, "awakeCount")
        row["sleep_resting_hr"] = g(d, "restingHeartRate")
        row["sleep_bb_change"] = g(d, "bodyBatteryChange")
        row["sleep_avg_resp"] = g(d, "averageRespirationValue")
        row["sleep_skin_temp_dev_c"] = g(d, "avgSkinTempDeviationC")

    # hrv.json
    h = load_json(date_dir / "hrv.json")
    if h:
        hs = g(h, "hrvSummary") or {}
        row["hrv_weekly_avg"] = g(hs, "weeklyAvg")
        row["hrv_night_avg"] = g(hs, "lastNightAvg")
        row["hrv_5min_high"] = g(hs, "lastNight5MinHigh")
        row["hrv_status"] = g(hs, "status")

    # body_battery.json (list)
    bb = load_json(date_dir / "body_battery.json")
    if bb and isinstance(bb, list) and len(bb) > 0:
        row["bb_charged"] = row.get("bb_charged") or g(bb, 0, "charged")
        row["bb_drained"] = row.get("bb_drained") or g(bb, 0, "drained")

    # training_readiness.json (list — take AFTER_WAKEUP_RESET or first entry)
    tr = load_json(date_dir / "training_readiness.json")
    if tr and isinstance(tr, list) and len(tr) > 0:
        best = None
        for entry in tr:
            if g(entry, "inputContext") == "AFTER_WAKEUP_RESET":
                best = entry
                break
        if best is None:
            best = tr[0]
        row["tr_score"] = g(best, "score")
        row["tr_level"] = g(best, "level")
        row["tr_recovery_time"] = g(best, "recoveryTime")

    # hydration.json
    hy = load_json(date_dir / "hydration.json")
    if hy:
        row["hydration_ml"] = g(hy, "valueInML")
        row["hydration_goal_ml"] = g(hy, "goalInML")
        row["sweat_loss_ml"] = g(hy, "sweatLossInML")

    # stress.json
    st = load_json(date_dir / "stress.json")
    if st:
        row["stress_avg"] = g(st, "avgStressLevel")
        row["stress_max"] = g(st, "maxStressLevel")

    # respiration.json
    rp = load_json(date_dir / "respiration.json")
    if rp:
        row["resp_avg_waking"] = g(rp, "avgWakingRespirationValue")
        row["resp_avg_sleep"] = g(rp, "avgSleepRespirationValue")

    return row


def extract_activity(filepath: Path) -> dict | None:
    """Extract one row of activity data from a {id}.json file."""
    data = load_json(filepath)
    if not data:
        return None

    s = data.get("summaryDTO", {})
    start = g(s, "startTimeLocal")
    date_str = start[:10] if start else None

    return {
        "id": g(data, "activityId"),
        "date": date_str,
        "type": g(data, "activityTypeDTO", "typeKey"),
        "name": g(data, "activityName"),
        "duration_s": g(s, "duration"),
        "moving_s": g(s, "movingDuration"),
        "distance_m": g(s, "distance"),
        "calories": g(s, "calories"),
        "avg_hr": g(s, "averageHR"),
        "max_hr": g(s, "maxHR"),
        "min_hr": g(s, "minHR"),
        "avg_speed_mps": g(s, "averageSpeed"),
        "elevation_gain_m": g(s, "elevationGain"),
        "elevation_loss_m": g(s, "elevationLoss"),
        "training_effect": g(s, "trainingEffect"),
        "anaerobic_te": g(s, "anaerobicTrainingEffect"),
        "training_load": g(s, "activityTrainingLoad"),
        "avg_cadence": g(s, "averageRunCadence"),
        "avg_power": g(s, "averagePower"),
        "max_power": g(s, "maxPower"),
        "moderate_im": g(s, "moderateIntensityMinutes"),
        "vigorous_im": g(s, "vigorousIntensityMinutes"),
        "steps": g(s, "steps"),
        "bb_change": g(s, "differenceBodyBattery"),
    }


def extract_body_comp() -> list[dict]:
    """Extract body composition rows from body_comp.json."""
    data = load_json(BODY_COMP_FILE)
    if not data:
        return []
    entries = g(data, "dateWeightList") or []
    rows = []
    for entry in entries:
        weight_raw = g(entry, "weight")
        rows.append({
            "date": g(entry, "calendarDate"),
            "weight_kg": round(weight_raw / 1000, 2) if weight_raw else None,
            "bmi": g(entry, "bmi"),
            "body_fat_pct": g(entry, "bodyFat"),
            "body_water_pct": g(entry, "bodyWater"),
            "bone_mass_g": g(entry, "boneMass"),
            "muscle_mass_g": g(entry, "muscleMass"),
        })
    rows.sort(key=lambda r: r.get("date") or "")
    return rows


def extract_personal_records() -> list[dict]:
    """Extract personal records from personal_records.json."""
    data = load_json(PERSONAL_RECORDS_FILE)
    if not data or not isinstance(data, list):
        return []
    rows = []
    for rec in data:
        type_id = g(rec, "typeId")
        date_str = g(rec, "actStartDateTimeInGMTFormatted")
        rows.append({
            "type": PR_TYPE_NAMES.get(type_id, f"type_{type_id}"),
            "value": g(rec, "value"),
            "activity_type": g(rec, "activityType"),
            "activity_name": g(rec, "activityName"),
            "date": date_str[:10] if date_str else None,
        })
    return rows


def extract_profile() -> str:
    """Extract key profile info as comment lines."""
    data = load_json(PROFILE_FILE)
    if not data:
        return ""
    ud = g(data, "userData") or {}
    lines = ["# PROFILE"]
    gender = g(ud, "gender")
    birth = g(ud, "birthDate")
    height = g(ud, "height")
    weight_raw = g(ud, "weight")
    weight = round(weight_raw / 1000, 1) if weight_raw else None
    vo2 = g(ud, "vo2MaxRunning")
    lt_hr = g(ud, "lactateThresholdHeartRate")
    lines.append(f"#   gender: {gender}, born: {birth}, height: {height}cm, weight: {weight}kg")
    lines.append(f"#   VO2max (running): {vo2}, lactate threshold HR: {lt_hr}bpm")
    return "\n".join(lines) + "\n"


def load_state() -> dict:
    """Load processing state, or return empty state."""
    state = load_json(STATE_FILE)
    if state and isinstance(state, dict):
        return state
    return {"processed_dates": [], "processed_activities": []}


def save_state(state: dict):
    STATE_FILE.write_text(json.dumps(state, indent=2) + "\n")


def rows_to_csv(columns: list[str], rows: list[dict]) -> str:
    """Convert rows to a CSV string."""
    buf = io.StringIO()
    writer = csv.DictWriter(buf, fieldnames=columns, extrasaction="ignore")
    writer.writeheader()
    for row in rows:
        writer.writerow(row)
    return buf.getvalue()


def read_existing_csv_section(section_marker: str) -> str:
    """Read an existing CSV section from the combined file, returns CSV text or empty string."""
    if not COMBINED_FILE.exists():
        return ""
    text = COMBINED_FILE.read_text()
    marker = f"# === {section_marker} ===\n"
    idx = text.find(marker)
    if idx == -1:
        return ""
    csv_start = idx + len(marker)
    # Find the next section marker or end of file
    next_marker = text.find("\n# === ", csv_start)
    if next_marker == -1:
        return text[csv_start:]
    return text[csv_start:next_marker]


def parse_csv_text(csv_text: str) -> list[dict]:
    """Parse CSV text into list of dicts."""
    csv_text = csv_text.strip()
    if not csv_text:
        return []
    reader = csv.DictReader(io.StringIO(csv_text))
    return list(reader)


def write_combined_file(
    daily_rows: list[dict],
    activity_rows: list[dict],
    body_comp_rows: list[dict],
    pr_rows: list[dict],
    profile_text: str,
):
    """Write the combined output file with header and all sections."""
    parts = [HEADER_TEXT]

    if profile_text:
        parts.append(profile_text)
        parts.append("\n")

    parts.append("# === DAILY_METRICS ===\n")
    parts.append(rows_to_csv(DAILY_COLUMNS, daily_rows))

    parts.append("# === BODY_COMPOSITION ===\n")
    parts.append(rows_to_csv(BODY_COMP_COLUMNS, body_comp_rows))

    parts.append("# === ACTIVITIES ===\n")
    parts.append(rows_to_csv(ACTIVITY_COLUMNS, activity_rows))

    parts.append("# === PERSONAL_RECORDS ===\n")
    parts.append(rows_to_csv(PR_COLUMNS, pr_rows))

    COMBINED_FILE.write_text("".join(parts))


def process_daily(state: dict) -> tuple[list[dict], int]:
    """Process daily data. Returns (all_rows, new_count)."""
    # Load existing rows from file
    existing_csv = read_existing_csv_section("DAILY_METRICS")
    existing_rows = parse_csv_text(existing_csv)

    if not DAILY_DIR.exists():
        print(f"Daily data directory not found: {DAILY_DIR}")
        return existing_rows, 0

    processed = set(state.get("processed_dates", []))
    all_dates = sorted(
        d.name for d in DAILY_DIR.iterdir() if d.is_dir() and d.name[:4].isdigit()
    )
    new_dates = [d for d in all_dates if d not in processed]

    if not new_dates:
        print("Daily: 0 new days to process")
        return existing_rows, 0

    new_rows = []
    for date_str in new_dates:
        row = extract_daily(DAILY_DIR / date_str)
        new_rows.append(row)

    all_rows = existing_rows + new_rows
    all_rows.sort(key=lambda r: r.get("date", ""))

    state["processed_dates"] = sorted(processed | set(new_dates))
    print(f"Daily: processed {len(new_dates)} new days ({new_dates[0]} to {new_dates[-1]})")
    return all_rows, len(new_dates)


def process_activities(state: dict) -> tuple[list[dict], int]:
    """Process activity files. Returns (all_rows, new_count)."""
    # Load existing rows from file
    existing_csv = read_existing_csv_section("ACTIVITIES")
    existing_rows = parse_csv_text(existing_csv)

    if not ACTIVITIES_DIR.exists():
        print("Activities: no activities directory found, skipping")
        return existing_rows, 0

    processed = set(state.get("processed_activities", []))
    all_files = sorted(
        f.stem for f in ACTIVITIES_DIR.iterdir()
        if f.is_file() and f.suffix == ".json"
    )
    new_ids = [fid for fid in all_files if fid not in processed]

    if not new_ids:
        print("Activities: 0 new activities to process")
        return existing_rows, 0

    new_rows = []
    for fid in new_ids:
        row = extract_activity(ACTIVITIES_DIR / f"{fid}.json")
        if row:
            new_rows.append(row)

    all_rows = existing_rows + new_rows
    all_rows.sort(key=lambda r: r.get("date") or "")

    state["processed_activities"] = sorted(processed | set(new_ids))
    print(f"Activities: processed {len(new_ids)} new activities")
    return all_rows, len(new_ids)


def main():
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    state = load_state()

    daily_rows, daily_new = process_daily(state)
    activity_rows, activity_new = process_activities(state)

    # These are small and always fully refreshed
    body_comp_rows = extract_body_comp()
    pr_rows = extract_personal_records()
    profile_text = extract_profile()

    if daily_new > 0 or activity_new > 0 or not COMBINED_FILE.exists():
        write_combined_file(daily_rows, activity_rows, body_comp_rows, pr_rows, profile_text)

    save_state(state)

    bc_msg = f", {len(body_comp_rows)} weigh-ins" if body_comp_rows else ""
    pr_msg = f", {len(pr_rows)} personal records" if pr_rows else ""
    print(f"\nSummary: {len(daily_rows)} days, {len(activity_rows)} activities{bc_msg}{pr_msg}")
    print(f"Output:  {COMBINED_FILE}")


if __name__ == "__main__":
    main()
